{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "665298da-8702-4c1e-8196-b648d3dcd6fe",
   "metadata": {},
   "source": [
    "# RetinaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3191d0-a746-41d8-a9a1-c0a42b8f31c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsRetinaNet()\n",
    "detector.setModelPath( os.path.join(execution_path , \"retinanet_resnet50_fpn_coco-eeacb38b.pth\"))\n",
    "detector.loadModel()\n",
    "detections = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , \"download.jpg\"), output_image_path=os.path.join(execution_path , \"download_retnet.jpg\"), minimum_percentage_probability=30)\n",
    "\n",
    "for eachObject in detections:\n",
    "    print(eachObject[\"name\"] , \" : \", eachObject[\"percentage_probability\"], \" : \", eachObject[\"box_points\"] )\n",
    "    print(\"--------------------------------\")\n",
    "\n",
    "\n",
    "im = Image.open(execution_path + '\\\\' + 'download_retnet.jpg')\n",
    "\n",
    "im.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d887afa-aec9-47c8-8ee9-187c7a3929b6",
   "metadata": {},
   "source": [
    "# Yolov3 (feasible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e325f1d6-a128-4509-bb6f-8879d0b27e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath( os.path.join(execution_path , \"yolov3.pt\"))\n",
    "detector.loadModel()\n",
    "detections = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , \"download.jpg\"), output_image_path=os.path.join(execution_path , \"download_yolo.jpg\"), minimum_percentage_probability=30)\n",
    "\n",
    "for eachObject in detections:\n",
    "    print(eachObject[\"name\"] , \" : \", eachObject[\"percentage_probability\"], \" : \", eachObject[\"box_points\"] )\n",
    "    print(\"--------------------------------\")\n",
    "    \n",
    "im = Image.open(execution_path + '\\\\' + 'download_yolo.jpg')\n",
    "\n",
    "im.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1241c7e-3dbb-4d0d-932f-a27d9330eaa5",
   "metadata": {},
   "source": [
    "# TinyYolov3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4e921c-94f9-4ba7-a7f0-11c7ccd1b3f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsTinyYOLOv3()\n",
    "detector.setModelPath( os.path.join(execution_path , \"tiny-yolov3.pt\"))\n",
    "detector.loadModel()\n",
    "detections = detector.detectObjectsFromImage(input_image=os.path.join(execution_path , \"download.jpg\"), output_image_path=os.path.join(execution_path , \"download_tiny_yolo.jpg\"), minimum_percentage_probability=30)\n",
    "\n",
    "for eachObject in detections:\n",
    "    print(eachObject[\"name\"] , \" : \", eachObject[\"percentage_probability\"], \" : \", eachObject[\"box_points\"] )\n",
    "    print(\"--------------------------------\")\n",
    "    \n",
    "im = Image.open(execution_path + '\\\\' + 'download_tiny_yolo.jpg')\n",
    "\n",
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977556b3-9fc5-4263-8556-e512e509c0b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e01793-fc3d-4a31-b835-2ed153d51cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed162b5-fe31-4a17-ad66-498b418bb393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf4b65c-2e4c-40bf-ba25-0c7ffdbf29a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f594bf34-e189-400d-83bd-1ff971b49ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f502702b-b871-4567-9d6c-900728b8252f",
   "metadata": {},
   "source": [
    "# Webcam Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a07c29d-e811-436b-80b9-1d5040e44640",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Jupyter\\HaarSucks\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "E:\\Jupyter\\HaarSucks\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "E:\\Jupyter\\HaarSucks\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained_backbone' is deprecated since 0.13 and may be removed in the future, please use 'weights_backbone' instead.\n",
      "  warnings.warn(\n",
      "E:\\Jupyter\\HaarSucks\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights_backbone' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights_backbone=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Frame :  1\n",
      "Processing Frame :  2\n",
      "Processing Frame :  3\n",
      "Processing Frame :  4\n",
      "Processing Frame :  5\n"
     ]
    }
   ],
   "source": [
    "from imageai.Detection import VideoObjectDetection\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "\n",
    "\n",
    "camera = cv2.VideoCapture(0)\n",
    "out = cv2.VideoWriter('output_video.avi',cv2.VideoWriter_fourcc(*'DIVX'), 60)\n",
    "\n",
    "\n",
    "detector = VideoObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath(os.path.join(execution_path , \"yolov3.pt\"))\n",
    "detector.loadModel()\n",
    "\n",
    "\n",
    "video_path = detector.detectObjectsFromVideo(\n",
    "                camera_input=camera,\n",
    "                output_file_path=os.path.join(execution_path, \"camera_detected_video\"),\n",
    "                frames_per_second=20, log_progress=True, minimum_percentage_probability=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "551df60f-c776-4c1b-b9eb-a14327c5edba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person  :  99.99  :  [11, 77, 429, 480]\n",
      "--------------------------------\n",
      "person  :  99.98  :  [25, 74, 523, 480]\n",
      "--------------------------------\n",
      "person  :  99.99  :  [15, 80, 419, 480]\n",
      "--------------------------------\n",
      "person  :  99.99  :  [10, 78, 418, 480]\n",
      "--------------------------------\n",
      "person  :  99.99  :  [20, 75, 544, 480]\n",
      "--------------------------------\n",
      "person  :  99.99  :  [16, 73, 545, 480]\n",
      "--------------------------------\n",
      "person  :  100.0  :  [21, 78, 532, 480]\n",
      "--------------------------------\n",
      "person  :  100.0  :  [23, 82, 538, 480]\n",
      "--------------------------------\n",
      "person  :  100.0  :  [21, 81, 542, 480]\n",
      "--------------------------------\n",
      "person  :  100.0  :  [21, 75, 546, 480]\n",
      "--------------------------------\n",
      "cup  :  97.4  :  [398, 342, 478, 419]\n",
      "--------------------------------\n",
      "person  :  99.98  :  [29, 65, 538, 480]\n",
      "--------------------------------\n",
      "person  :  99.98  :  [72, 78, 557, 480]\n",
      "--------------------------------\n",
      "chair  :  98.32  :  [41, 355, 130, 477]\n",
      "--------------------------------\n",
      "person  :  100.0  :  [15, 77, 547, 480]\n",
      "--------------------------------\n",
      "person  :  100.0  :  [14, 83, 544, 480]\n",
      "--------------------------------\n",
      "person  :  100.0  :  [14, 80, 544, 480]\n",
      "--------------------------------\n",
      "person  :  99.99  :  [16, 78, 544, 480]\n",
      "--------------------------------\n",
      "person  :  100.0  :  [21, 85, 538, 475]\n",
      "--------------------------------\n",
      "person  :  100.0  :  [15, 83, 544, 479]\n",
      "--------------------------------\n",
      "person  :  100.0  :  [20, 83, 535, 479]\n",
      "--------------------------------\n",
      "person  :  99.99  :  [20, 69, 508, 480]\n",
      "--------------------------------\n",
      "person  :  99.9  :  [20, 75, 443, 480]\n",
      "--------------------------------\n",
      "bottle  :  79.5  :  [261, 103, 411, 474]\n",
      "--------------------------------\n",
      "person  :  99.59  :  [381, 79, 637, 472]\n",
      "--------------------------------\n",
      "person  :  68.53  :  [96, 8, 549, 480]\n",
      "--------------------------------\n",
      "person  :  83.38  :  [55, 0, 474, 474]\n",
      "--------------------------------\n",
      "remote  :  60.83  :  [243, 18, 433, 452]\n",
      "--------------------------------\n",
      "person  :  93.98  :  [104, 0, 619, 478]\n",
      "--------------------------------\n",
      "bottle  :  59.92  :  [253, 11, 426, 460]\n",
      "--------------------------------\n",
      "person  :  95.78  :  [73, 0, 577, 480]\n",
      "--------------------------------\n",
      "bottle  :  74.92  :  [256, 16, 421, 462]\n",
      "--------------------------------\n",
      "person  :  99.95  :  [33, 79, 509, 479]\n",
      "--------------------------------\n",
      "person  :  93.15  :  [456, 27, 640, 452]\n",
      "--------------------------------\n",
      "person  :  99.99  :  [27, 58, 503, 480]\n",
      "--------------------------------\n",
      "person  :  99.21  :  [462, 34, 636, 445]\n",
      "--------------------------------\n",
      "person  :  99.99  :  [46, 63, 485, 480]\n",
      "--------------------------------\n",
      "person  :  99.97  :  [29, 72, 515, 480]\n",
      "--------------------------------\n",
      "person  :  100.0  :  [18, 90, 524, 480]\n",
      "--------------------------------\n",
      "person  :  100.0  :  [21, 80, 527, 480]\n",
      "--------------------------------\n",
      "person  :  99.99  :  [22, 84, 524, 480]\n",
      "--------------------------------\n",
      "person  :  99.99  :  [19, 90, 519, 480]\n",
      "--------------------------------\n",
      "person  :  99.99  :  [20, 88, 525, 480]\n",
      "--------------------------------\n",
      "person  :  99.99  :  [21, 90, 521, 480]\n",
      "--------------------------------\n",
      "person  :  99.99  :  [26, 89, 521, 480]\n",
      "--------------------------------\n",
      "person  :  99.99  :  [21, 95, 522, 480]\n",
      "--------------------------------\n",
      "person  :  99.99  :  [19, 93, 526, 480]\n",
      "--------------------------------\n",
      "person  :  99.99  :  [17, 88, 522, 480]\n",
      "--------------------------------\n",
      "person  :  99.98  :  [26, 101, 512, 479]\n",
      "--------------------------------\n",
      "person  :  99.98  :  [14, 99, 511, 480]\n",
      "--------------------------------\n",
      "chair  :  93.68  :  [29, 352, 109, 476]\n",
      "--------------------------------\n",
      "person  :  99.99  :  [0, 88, 470, 480]\n",
      "--------------------------------\n",
      "person  :  100.0  :  [47, 105, 488, 478]\n",
      "--------------------------------\n",
      "chair  :  99.0  :  [40, 349, 83, 454]\n",
      "--------------------------------\n",
      "person  :  99.96  :  [112, 81, 507, 480]\n",
      "--------------------------------\n",
      "chair  :  99.68  :  [39, 352, 119, 476]\n",
      "--------------------------------\n",
      "person  :  100.0  :  [29, 91, 486, 480]\n",
      "--------------------------------\n",
      "person  :  99.99  :  [41, 99, 475, 479]\n",
      "--------------------------------\n",
      "person  :  100.0  :  [35, 96, 480, 479]\n",
      "--------------------------------\n",
      "person  :  99.99  :  [69, 87, 489, 480]\n",
      "--------------------------------\n",
      "chair  :  99.16  :  [39, 349, 91, 464]\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "import cv2\n",
    "import numpy\n",
    "#from PIL import Image\n",
    "\n",
    "\n",
    "def imageai_detect(frame):\n",
    "    execution_path = os.getcwd()\n",
    "    frame_yolo = os.path.join(execution_path , \"frame_yolo.jpg\") \n",
    "\n",
    "    detector = ObjectDetection()\n",
    "    detector.setModelTypeAsYOLOv3()\n",
    "    detector.setModelPath(os.path.join(execution_path , \"yolov3.pt\"))\n",
    "    detector.loadModel()\n",
    "    detections = detector.detectObjectsFromImage(input_image=frame, output_image_path=frame_yolo, minimum_percentage_probability=30)\n",
    "\n",
    "    for eachObject in detections:\n",
    "        print(eachObject[\"name\"] , \" : \", eachObject[\"percentage_probability\"], \" : \", eachObject[\"box_points\"] )\n",
    "        print(\"--------------------------------\")\n",
    "    return frame_yolo\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    _, frame = cap.read()\n",
    "    yolo = imageai_detect(frame)\n",
    "    \n",
    "    image = cv2.imread(yolo)\n",
    "    #pil_yolo = Image.open(yolo)\n",
    "    np_yolo = numpy.array(image)\n",
    "    \n",
    "    cv2.imshow('ImageAI Webcam', np_yolo)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a29cadf-ca71-4fce-b3c1-7e597b325bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haarsucks",
   "language": "python",
   "name": "haarsucks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
